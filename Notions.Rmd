---
title: "Notions mathématiques"
description: |
  Un rappel sur les notions mathématiques nécessaires à la compréhension des modèles
site: distill::distill_website
---

```{r, echo=FALSE}
library(ggplot2)
```

# Les notions d'inertie

-   **Inertie totale**

On appelle inertie totale d'un nuage de points la somme pondérée des carrés des distances de ces points au centre de gravité du nuage. Si $z$ désigne le centre de gravité du nuage $X = (x_i, x_2, ...,x_n)$, l'inertie totale du nuage peut s'écrire : 

$$
I_X(z)=\sum_{i=1}^np_id(x_i,z)^2
$$

Notons que le centre de gravité est précisément le point $z$ pour lequel cette somme pondérée est minimale. L'inertie mesure la dispersion du nuage. Le nuage peut cependant être composé de plusieurs classes.

-   **Inertie intraclasse**

Lorsque le nuage de points est composé de plusieurs classes, il est possible de calculer l'inertie intraclasse. Cette inertie correspond à la somme des inerties de chaque classe du nuage de points. Si le nuage de points $X$ est composé de $k$ classes $(X_1, X_2,...,X_k)$ de centre de gravité respectif $(z_1, z_2,...,z_k)$, l'inertie intraclasse s'écrit :

$$
I_{intraclasse} = \sum_{k=1}^nI_{X_k}(z_k).
$$

-   **Inertie interclasse**

L'inertie interclasse correspond à la dispersion des différentes classes par rapport au centre de gravité du nuage de points. On peut donc l'écrire : 

$$
I_{interclasse} = \sum_{k=1}^nP_kd(z_k,z)^2.
$$

L'inertie totale d'un nuage de points composé de différentes classes disjointes deux à deux est la somme de son inertie intraclasse et de son inertie interclasse : 

$$
I_{totale} = I_{intraclasse} + I_{interclasse}.
$$

Par exemple, pour un nuage de 8 points répartis en deux classes, on peut représenter ces inerties graphiquement ainsi :

```{r inertie ggplot, echo=FALSE,fig.height=4,fig.width=8}
ggplot()+
  geom_point(aes(x=c(1,1.5,2.5,3), y=c(1,1,1,1)), color = "#344a58") +
  geom_point(aes(x=c(7,7.5,8.5,9), y=c(1,1,1,1)), color = "#238694") +
  geom_point(aes(x=c(2), y=c(1)), color = "pink") +
  geom_point(aes(x=c(8), y=c(1)), color = "pink") +
  geom_segment(aes(x=1, y=1.05, xend =9, yend=1.05),arrow = arrow(length = unit(0.3, "cm"))) +
  geom_segment(aes(x=9, y=1.05, xend =1, yend=1.05),arrow = arrow(length = unit(0.3, "cm"))) +
  geom_segment(aes(x=2, y=0.93, xend =8, yend=0.93),arrow = arrow(length = unit(0.3, "cm"))) +
  geom_segment(aes(x=8, y=0.93, xend =2, yend=0.93),arrow = arrow(length = unit(0.3, "cm"))) +
  geom_segment(aes(x=1, y=0.83, xend =3, yend=0.83),arrow = arrow(length = unit(0.3, "cm"))) +
  geom_segment(aes(x=3, y=0.83, xend =1, yend=0.83),arrow = arrow(length = unit(0.3, "cm"))) +
  geom_segment(aes(x=7, y=0.83, xend =9, yend=0.83),arrow = arrow(length = unit(0.3, "cm"))) +
  geom_segment(aes(x=9, y=0.83, xend =7, yend=0.83),arrow = arrow(length = unit(0.3, "cm"))) + 
  annotate("text", x = 2, y = 0.98, label = "z1")+ 
  annotate("text", x = 8, y = 0.98, label = "z2")+ 
  annotate("text", x = 5, y = 1.1, label = "Inertie totale")+ 
  annotate("text", x = 5, y = 0.88, label = "Inertie interclasse")+ 
  annotate("text", x = 2, y = 0.78, label = "Inertie intraclasse X1")+ 
  annotate("text", x = 8, y = 0.78, label = "Inertie intraclasse X2") + 
  theme_classic()+
  theme(axis.ticks = element_blank(),
        axis.text = element_blank(),
        panel.background = element_blank(),
        legend.position = "top",
        plot.title = element_blank(),
        axis.title = element_blank(),
        axis.line = element_blank()) 
  
  
```



# Les notions de distance

En analyse de données, il est important de définir des *métriques* ou des *fonctions de distance* pour mesurer les similarités. Avant de commencer à discuter des métriques de distance, définissons quelques règles de base pour une fonction de distance valide. Les conditions qu'une fonction de distance doit satisfaire sont:

1.  **Non-négativité :** $d(x,y)\geq 0$. La distance doit toujours être supérieure à $0$.

2.  **Identité :** $d(x,y)=0$, si et seulement si, $x=y$.

3.  **Symétrie :** $d(x,y)=d(y,x)$. La distance entre le point $x$ et $y$ est la même que la distance entre le point $y$ et $x$.

4.  **Inégalité triangulaire :** $d(x,y)+d(y,z)\geq d(x,z)$. Un troisième point ne peut jamais raccourcir la distance entre les deux autres points.

Il existe différentes méthodes pour calculer une distance. La liste suivante en répertorie quelques unes d'entre elles.

-   **La distance euclidienne :**

$$
d_{euclienne}(x,y) = \sqrt{\sum_{i}(x_i - y_i)^2},
$$
où $x = x_1, x_2,\cdots, x_m$ et $y = y_1, y_2, \cdots, y_m$ représentent les $m$ valeurs des variables de deux enregistrements.


La *distance euclidienne* entre deux points est la longueur d'un segment de ligne entre les deux points. Cette distance est la plus courante, et représente la manière habituelle de penser une distance dans la vie courante. De manière graphique, on peut la représenter ainsi:

```{r eucli, echo=FALSE}
ggplot()+
  geom_segment(aes(x=1, y=2, xend =2, yend=1),arrow = arrow(length = unit(0.3, "cm")), color = "#238694") +
  geom_segment(aes(x=2, y=1, xend =1, yend=2),arrow = arrow(length = unit(0.3, "cm")), color = "#238694") +
  geom_point(aes(x=2, y=1), colour = "#344a58", size = 3)+ geom_point(aes(x=1, y=2), color = "#344a58", size =3)+ theme_classic()+
  theme(axis.ticks = element_blank(),
        panel.background = element_blank(),
        legend.position = "top",
        plot.title = element_text(size=14, face="bold",hjust = 0.5),
        axis.title.x = element_text(size=12, face="bold"),
        axis.title.y = element_text(size=12, face="bold"),
        legend.text = element_text(size = 12))+ 
  ggtitle("Distance euclidienne")
```

-   **La distance de Manhattan :**

$$
d_{Manhattan}(x,y)=\sum_i |x_i-y_i|.
$$

La *distance de Manhattan* est la distance entre deux points parcourue par un taxi lorsqu'il se déplace dans une ville où les rues sont agencées selon un réseau ou quadrillage. De manière graphique, on peut la représenter ainsi:

```{r dist manha, echo=FALSE}
ggplot()+
  geom_segment(aes(x=2, y=2, xend =1, yend=2),arrow = arrow(length = unit(0.3, "cm")), color = "#238694") +
  geom_segment(aes(x=2, y=2, xend =2, yend=1),arrow = arrow(length = unit(0.3, "cm")), color = "#238694") +
  geom_point(aes(x=2, y=1), colour = "#344a58", size = 3)+ geom_point(aes(x=1, y=2), color = "#344a58", size =3)+ theme_classic()+
  theme(axis.ticks = element_blank(),
        panel.background = element_blank(),
        legend.position = "top",
        plot.title = element_text(size=14, face="bold",hjust = 0.5),
        axis.title.x = element_text(size=12, face="bold"),
        axis.title.y = element_text(size=12, face="bold"),
        legend.text = element_text(size = 12)) + 
  ggtitle("Distance de Manhatan")
```

-   **La distance de Minkowski :**

$$
d_{Minkowski}(x,y)=\Big(\sum_i |x_i-y_i|^q\Big)^\frac{1}{q},
$$ 

La *distance de Minkowski* est une métrique dans un espace vectoriel normé qui peut être considérée comme une généralisation de la *distance euclidienne* et de la *distance de Manhattan*. En effet, lorsque $p=2$, on retrouve la formule de la *distance euclidienne* et lorsque que $p=1$, on retrouve la formule de la *distance de Manhattan*.

```{r minko, echo=F}
ggplot()+
  geom_curve(aes(x=1, y=2, xend =2, yend=1), curvature = 0.3,arrow = arrow(length = unit(0.3, "cm")), color = "#238694") +
  geom_curve(aes(x=2, y=1, xend =1, yend=2), curvature = -0.3,arrow = arrow(length = unit(0.3, "cm")), color = "#238694") +
  geom_point(aes(x=2, y=1), colour = "#344a58", size = 3)+ geom_point(aes(x=1, y=2), color = "#344a58", size =3)+ theme_classic()+
  theme(axis.ticks = element_blank(),
        panel.background = element_blank(),
        legend.position = "top",
        plot.title = element_text(size=14, face="bold",hjust = 0.5),
        axis.title.x = element_text(size=12, face="bold"),
        axis.title.y = element_text(size=12, face="bold"),
        legend.text = element_text(size = 12)) + 
  ggtitle("Distance  de Minkowski")
```

-   **La distance de Chebyshev :**

$$
d_{Chebyshev}(x,y)= \max_{i \in [[0,n]]} (|x_i - y_i|)
$$


La *distance de Chebyshev* est la distance entre deux points donnée par la différence maximale entre leurs coordonnées sur une dimension. Le calcul d'une *distance de Chebychev* ne fait intervenir que des soustractions, des valeurs absolues (donc des changements de signe) et des comparaisons (recherche de la valeur maximale). Elle est donc moins sujette aux erreurs numériques qu'une distance quadratique, qui elle, calcule des sommes de carrés. De plus, elle sera calculée plus rapidement.


```{r cherby, echo=FALSE}
ggplot()+
  geom_segment(aes(x=1, y=2, xend =2, yend=2),arrow = arrow(length = unit(0.3, "cm")), color = "#238694") + 
  geom_segment(aes(x=2, y=2, xend =1, yend=2),arrow = arrow(length = unit(0.3, "cm")), color = "#238694") +
  geom_point(aes(x=2, y=1), colour = "#344a58", size = 3)+ geom_point(aes(x=1, y=2), color = "#344a58", size =3)+ theme_classic()+
  theme(axis.ticks = element_blank(),
        panel.background = element_blank(),
        legend.position = "top",
        plot.title = element_text(size=14, face="bold",hjust = 0.5),
        axis.title.x = element_text(size=12, face="bold"),
        axis.title.y = element_text(size=12, face="bold"),
        legend.text = element_text(size = 12)) + 
  ggtitle("Distance de Cherbyshev")
```


# Centre de gravité, variances intra et inter classes

On considère $n$ individus $x_i$ qui constituent un nuage $E$ de $\mathbb{R}^p$ dont les coordonnées sont les valeurs prises par les prédicteurs. La variable à expliquer partage ce nuage en $k$ sous-nuages, de centres de gravité respectifs $\bar x^1,\cdots,\bar{x}^k$ et de matrices de variances-covariance $V_1, V_2,\cdots , V_k$. On note $\bar x$ le centre de gravité et $V$ la matrice de variance de $E$ tout entier.

En supposant que les individus ont le même poids, on a les relations suivantes :

- **Centre de gravité :**

$$
\bar x=\frac{1}{n}\sum^k_{i=1}n_j\bar x^j,
$$

- **Matrices de variances-covariances :**

$$
V_j=\frac{1}{n}\sum^n_{i\in I_j}(x_i-\bar x^j)(x_i-\bar x^j)^t,
$$

- **Matrice de variances interclasse :**

$$
B=\frac{1}{n}\sum^n_{j=1}n_j(\bar x^j-\bar x)(\bar x^j-\bar x)^t,
$$

- **Matrice de variances intraclasse :**

$$
W=\frac{1}{n}\sum^n_{i=1}n_jV_j.
$$






